{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse CSE File to Get Course List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "course_type = 'CSE'\n",
    "pdfFileObj = open('ComputingScienceSummaries.pdf', 'rb')\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "  \n",
    "n_pages = len(pdfReader.pages)\n",
    "text = ''\n",
    "\n",
    "for n in range(n_pages):\n",
    "    pageObj = pdfReader.pages[n]\n",
    "    text += pageObj.extract_text()\n",
    "\n",
    "pdfFileObj.close()\n",
    "\n",
    "courses = {}\n",
    "use_next_line = False\n",
    "\n",
    "for i, line in enumerate(text.splitlines()):\n",
    "    if line.strip().startswith(course_type) and line[9] == ' ':\n",
    "        course = line.replace('  ', ' ').strip()\n",
    "    if '©' in line and course_type in line:\n",
    "        # 100 © Alberta Education, Alberta, Canada   Revised 2010  CSE2910:  CSE PROJECT B  \n",
    "        course = course_type + line.split(course_type)[1]\n",
    "        course = course.replace('  ', ' ').strip()\n",
    "    if 'Prerequ' in line:\n",
    "        preq = line.split(': ')[1].strip().replace(' ', '')\n",
    "        if 'None' in preq:\n",
    "            preq = ''\n",
    "        courses[course] = [preq]\n",
    "    if use_next_line:\n",
    "        #print('True', line)\n",
    "        preq2 = line.split(': ')[0].strip().replace(' ', '')\n",
    "        if len(preq2) != 0: # in case there is no prereq on this line\n",
    "            preq = preq + ',' + preq2\n",
    "        courses[course] = [preq]\n",
    "        use_next_line = False\n",
    "    if 'Prerequisites' in line:\n",
    "        #print('use next line', line)\n",
    "        #print(i, course, preq, '---', line)\n",
    "        use_next_line = True\n",
    "    #if '1120' in line:\n",
    "    #if '1010' in line:\n",
    "    #    print(i, use_next_line, line)\n",
    "df = pd.DataFrame.from_dict(courses, orient='index', columns=['Prerequisites']).reset_index()\n",
    "df.columns = ['Course', 'Prerequisites']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(text.splitlines()):\n",
    "    if '©' in line:\n",
    "        print(i, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Prerequisites'].str.contains(course_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Course'].str[3]=='3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(course_type+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "\n",
    "for row in df.itertuples():\n",
    "    course_number = row.Course.split(':')[0]\n",
    "    if '50' not in course_number:\n",
    "        if course_number[3] == '3':\n",
    "            dot.node(course_number, shape='diamond')\n",
    "        else:\n",
    "            dot.node(course_number, shape='box')\n",
    "        if row.Prerequisites != '':\n",
    "            for preq in row.Prerequisites.split(','):\n",
    "                dot.edge(preq, course_number)\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output to a file\n",
    "dot.render(course_type, view=True)\n",
    "import os\n",
    "# delete file\n",
    "os.remove(course_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NET Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "course_type = 'NET'\n",
    "pdfFileObj = open('NetworkingSummary.pdf', 'rb')\n",
    "\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "n_pages = len(pdfReader.pages)\n",
    "text = ''\n",
    "for n in range(n_pages):\n",
    "    pageObj = pdfReader.pages[n]\n",
    "    text += pageObj.extract_text()\n",
    "pdfFileObj.close()\n",
    "\n",
    "courses = {}\n",
    "use_next_line = False\n",
    "\n",
    "for i, line in enumerate(text.splitlines()):\n",
    "    if line.strip().startswith(course_type):# and line[9] == ' ':\n",
    "        course = line.replace('  ', ' ').strip()\n",
    "        use_next_line = False\n",
    "    if '©' in line and course_type in line and ':' in line:\n",
    "        course = line.split(':')[0].strip().split(' ')[-1] + ':' + line.split(':')[1].strip()\n",
    "        use_next_line = False\n",
    "    if 'Prerequ' in line:\n",
    "        try:\n",
    "            preq = line.split(':')[1].strip().replace(' ', '')\n",
    "        except:\n",
    "            preq = ''\n",
    "        if 'None' in preq:\n",
    "            preq = ''\n",
    "        courses[course] = [preq]\n",
    "    if use_next_line:\n",
    "        preq2 = line.split(': ')[0].strip().replace(' ', '')\n",
    "        if len(preq2) != 0: # in case there is no prereq on this line\n",
    "            preq = preq + ',' + preq2\n",
    "        courses[course] = [preq]\n",
    "    if 'Prerequisites' in line:\n",
    "        use_next_line = True\n",
    "df = pd.DataFrame.from_dict(courses, orient='index', columns=['Prerequisites']).reset_index()\n",
    "df.columns = ['Course', 'Prerequisites']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Prerequisites'] = df['Prerequisites'].str.replace('NET2030','NET2030,NET2040,NET2050,NET2060,NET2070')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Prerequisites'].str.contains(course_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "\n",
    "for row in df.itertuples():\n",
    "    course_number = row.Course.split(':')[0]\n",
    "    if '50' not in course_number:\n",
    "        if course_number[3] == '3':\n",
    "            dot.node(course_number, shape='diamond')\n",
    "        else:\n",
    "            dot.node(course_number, shape='box')\n",
    "        if row.Prerequisites != '':\n",
    "            for preq in row.Prerequisites.split(','):\n",
    "                dot.edge(preq, course_number)\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output to a file\n",
    "dot.render(course_type, view=True)\n",
    "import os\n",
    "# delete file\n",
    "os.remove(course_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFMiner.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        # Create a PDF parser object\n",
    "        parser = PDFParser(fh)\n",
    "        \n",
    "        # Create a PDF document object that stores the document structure\n",
    "        document = PDFDocument(parser)\n",
    "        \n",
    "        # Connect the parser and document objects\n",
    "        parser.set_document(document)\n",
    "        \n",
    "        # Create a PDF resource manager object that stores shared resources\n",
    "        resource_manager = PDFResourceManager()\n",
    "        \n",
    "        # Create a buffer for the extracted text\n",
    "        text_buffer = StringIO()\n",
    "        \n",
    "        # Create a PDF page aggregator object\n",
    "        device = TextConverter(resource_manager, text_buffer, laparams=LAParams())\n",
    "        \n",
    "        # Create a PDF interpreter object\n",
    "        interpreter = PDFPageInterpreter(resource_manager, device)\n",
    "        \n",
    "        # Process each page contained in the document\n",
    "        for page in PDFPage.create_pages(document):\n",
    "            interpreter.process_page(page)\n",
    "        \n",
    "        # Get the extracted text\n",
    "        text = text_buffer.getvalue()\n",
    "        \n",
    "        # Close the text buffer\n",
    "        text_buffer.close()\n",
    "        \n",
    "        # Close the device\n",
    "        device.close()\n",
    "        \n",
    "        # Return the extracted text\n",
    "        return text\n",
    "\n",
    "# Extract text from a PDF\n",
    "pdf_text = extract_text_from_pdf('ComputerScienceSummaries.pdf')\n",
    "\n",
    "# Print the extracted text\n",
    "print(pdf_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
